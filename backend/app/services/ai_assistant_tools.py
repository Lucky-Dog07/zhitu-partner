"""
AIåŠ©æ‰‹çš„Custom Tools - ç”¨äºè®¿é—®ç”¨æˆ·å­¦ä¹ æ•°æ®
"""
from langchain.tools import BaseTool
from typing import Type, Optional, List, Dict, Any
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session
from ..models.question_status import QuestionStatus
from ..models.interview_question import InterviewQuestion
from ..models.learning_path import LearningPath
from ..core.database import SessionLocal


# Tool Input Schemas (simplified - no user_id needed)
class GetMistakesInput(BaseModel):
    """é”™é¢˜æŸ¥è¯¢è¾“å…¥ - å…è®¸ç©ºå‚æ•°"""
    pass  # No required input


class GetLearningPathInput(BaseModel):
    pass  # No input needed


class GetQuestionStatsInput(BaseModel):
    pass  # No input needed


class AnalyzeMistakesInput(BaseModel):
    pass  # No input needed


class GetInterviewQuestionsInput(BaseModel):
    """é¢è¯•é¢˜æŸ¥è¯¢è¾“å…¥ - å…è®¸ç©ºå‚æ•°"""
    pass  # No required input


# Custom Tools
class GetMistakesTool(BaseTool):
    """è·å–ç”¨æˆ·é”™é¢˜çš„å·¥å…·"""
    name: str = "get_mistakes"
    description: str = "è·å–ç”¨æˆ·çš„é”™é¢˜åˆ—è¡¨ï¼ŒåŒ…æ‹¬é¢˜ç›®ã€ç­”æ¡ˆå’ŒçŸ¥è¯†ç‚¹ã€‚ç”¨äºåˆ†æç”¨æˆ·çš„è–„å¼±ç¯èŠ‚ã€‚"
    args_schema: Type[BaseModel] = GetMistakesInput
    user_id: int = Field(default=0, description="å½“å‰ç”¨æˆ·ID")
    
    def _run(self) -> str:
        """æŸ¥è¯¢ç”¨æˆ·é”™é¢˜"""
        db = SessionLocal()
        try:
            # æŸ¥è¯¢ç”¨æˆ·çš„é”™é¢˜ï¼ˆé»˜è®¤10æ¡ï¼‰
            mistakes = db.query(QuestionStatus).filter(
                QuestionStatus.user_id == self.user_id,
                QuestionStatus.status == "not_mastered"
            ).join(InterviewQuestion).limit(10).all()
            
            if not mistakes:
                return "ç”¨æˆ·ç›®å‰æ²¡æœ‰é”™é¢˜è®°å½•ã€‚"
            
            result = f"æ‰¾åˆ° {len(mistakes)} é“é”™é¢˜ï¼š\n\n"
            for i, mistake in enumerate(mistakes, 1):
                q = mistake.question
                result += f"{i}. **é¢˜ç›®**: {q.question[:100]}...\n"
                result += f"   **åˆ†ç±»**: {q.category or 'æœªåˆ†ç±»'}\n"
                result += f"   **éš¾åº¦**: {q.difficulty}\n"
                result += f"   **çŸ¥è¯†ç‚¹**: {', '.join(q.knowledge_points) if q.knowledge_points else 'æ— '}\n"
                result += f"   **ç­”æ¡ˆ**: {q.answer[:150]}...\n\n"
            
            return result
        finally:
            db.close()


class GetLearningPathTool(BaseTool):
    """è·å–ç”¨æˆ·å­¦ä¹ è·¯çº¿çš„å·¥å…·"""
    name: str = "get_learning_path"
    description: str = "è·å–ç”¨æˆ·çš„å­¦ä¹ è·¯çº¿å’Œç›®æ ‡èŒä½ä¿¡æ¯ã€‚ç”¨äºäº†è§£ç”¨æˆ·çš„å­¦ä¹ æ–¹å‘å’Œå·²ç”Ÿæˆçš„å­¦ä¹ å†…å®¹ã€‚"
    args_schema: Type[BaseModel] = GetLearningPathInput
    user_id: int = Field(default=0, description="å½“å‰ç”¨æˆ·ID")
    
    def _run(self) -> str:
        """æŸ¥è¯¢ç”¨æˆ·å­¦ä¹ è·¯çº¿"""
        db = SessionLocal()
        try:
            paths = db.query(LearningPath).filter(
                LearningPath.user_id == self.user_id
            ).order_by(LearningPath.created_at.desc()).limit(3).all()
            
            if not paths:
                return "ç”¨æˆ·è¿˜æ²¡æœ‰åˆ›å»ºå­¦ä¹ è·¯çº¿ã€‚"
            
            result = f"ç”¨æˆ·çš„å­¦ä¹ è·¯çº¿ï¼ˆæœ€è¿‘{len(paths)}ä¸ªï¼‰ï¼š\n\n"
            for i, path in enumerate(paths, 1):
                result += f"{i}. **ç›®æ ‡èŒä½**: {path.position}\n"
                if path.job_description:
                    result += f"   **èŒä½æè¿°**: {path.job_description[:100]}...\n"
                
                # åˆ†æå·²ç”Ÿæˆçš„å†…å®¹
                if path.generated_content:
                    content_types = []
                    if path.generated_content.get('mindmap'):
                        content_types.append('æ€ç»´å¯¼å›¾')
                    if path.generated_content.get('knowledge'):
                        content_types.append('çŸ¥è¯†ç‚¹è¯¦è§£')
                    if path.generated_content.get('interview'):
                        content_types.append('é¢è¯•é¢˜åº“')
                    if content_types:
                        result += f"   **å·²ç”Ÿæˆå†…å®¹**: {', '.join(content_types)}\n"
                
                result += f"   **åˆ›å»ºæ—¶é—´**: {path.created_at.strftime('%Y-%m-%d')}\n\n"
            
            return result
        finally:
            db.close()


class GetQuestionStatsTool(BaseTool):
    """è·å–ç”¨æˆ·å­¦ä¹ ç»Ÿè®¡æ•°æ®çš„å·¥å…·"""
    name: str = "get_question_stats"
    description: str = "è·å–ç”¨æˆ·çš„å­¦ä¹ ç»Ÿè®¡æ•°æ®ï¼ŒåŒ…æ‹¬å·²æŒæ¡ã€æœªæŒæ¡ã€æ€»é¢˜æ•°ç­‰ã€‚ç”¨äºè¯„ä¼°å­¦ä¹ è¿›åº¦ã€‚"
    args_schema: Type[BaseModel] = GetQuestionStatsInput
    user_id: int = Field(default=0, description="å½“å‰ç”¨æˆ·ID")
    
    def _run(self) -> str:
        """ç»Ÿè®¡ç”¨æˆ·å­¦ä¹ æ•°æ®"""
        db = SessionLocal()
        try:
            # ç»Ÿè®¡å„çŠ¶æ€çš„é¢˜ç›®æ•°é‡
            total = db.query(QuestionStatus).filter(
                QuestionStatus.user_id == self.user_id
            ).count()
            
            mastered = db.query(QuestionStatus).filter(
                QuestionStatus.user_id == self.user_id,
                QuestionStatus.status == "mastered"
            ).count()
            
            not_mastered = db.query(QuestionStatus).filter(
                QuestionStatus.user_id == self.user_id,
                QuestionStatus.status == "not_mastered"
            ).count()
            
            not_seen = total - mastered - not_mastered
            
            if total == 0:
                return "ç”¨æˆ·è¿˜æ²¡æœ‰å¼€å§‹ç»ƒä¹ é¢˜ç›®ã€‚"
            
            mastery_rate = (mastered / total * 100) if total > 0 else 0
            
            result = f"ğŸ“Š **å­¦ä¹ ç»Ÿè®¡æ•°æ®**ï¼š\n\n"
            result += f"- æ€»é¢˜æ•°: {total}\n"
            result += f"- å·²æŒæ¡: {mastered} ({mastered/total*100:.1f}%)\n"
            result += f"- æœªæŒæ¡: {not_mastered} ({not_mastered/total*100:.1f}%)\n"
            result += f"- æœªç»ƒä¹ : {not_seen} ({not_seen/total*100:.1f}%)\n"
            result += f"- æŒæ¡ç‡: {mastery_rate:.1f}%\n\n"
            
            if mastery_rate >= 80:
                result += "âœ… å­¦ä¹ è¿›åº¦ä¼˜ç§€ï¼ç»§ç»­ä¿æŒï¼"
            elif mastery_rate >= 60:
                result += "ğŸ‘ å­¦ä¹ è¿›åº¦è‰¯å¥½ï¼Œç»§ç»­åŠªåŠ›ï¼"
            elif mastery_rate >= 40:
                result += "ğŸ’ª è¿˜éœ€è¦åŠ æ²¹ï¼Œå»ºè®®é‡ç‚¹å¤ä¹ é”™é¢˜ã€‚"
            else:
                result += "âš ï¸ éœ€è¦åŠ å¼ºå­¦ä¹ ï¼Œå»ºè®®ç³»ç»Ÿå¤ä¹ çŸ¥è¯†ç‚¹ã€‚"
            
            return result
        finally:
            db.close()


class AnalyzeMistakesTool(BaseTool):
    """åˆ†æç”¨æˆ·é”™é¢˜çŸ¥è¯†ç‚¹åˆ†å¸ƒçš„å·¥å…·"""
    name: str = "analyze_mistakes"
    description: str = "æ·±åº¦åˆ†æç”¨æˆ·é”™é¢˜çš„çŸ¥è¯†ç‚¹åˆ†å¸ƒï¼Œæ‰¾å‡ºè–„å¼±ç¯èŠ‚ã€‚è¿”å›Topè–„å¼±çŸ¥è¯†ç‚¹å’Œå»ºè®®ã€‚"
    args_schema: Type[BaseModel] = AnalyzeMistakesInput
    user_id: int = Field(default=0, description="å½“å‰ç”¨æˆ·ID")
    
    def _run(self) -> str:
        """åˆ†æé”™é¢˜çŸ¥è¯†ç‚¹åˆ†å¸ƒ"""
        db = SessionLocal()
        try:
            # è·å–æ‰€æœ‰é”™é¢˜
            mistakes = db.query(QuestionStatus).filter(
                QuestionStatus.user_id == self.user_id,
                QuestionStatus.status == "not_mastered"
            ).join(InterviewQuestion).all()
            
            if not mistakes:
                return "ç”¨æˆ·ç›®å‰æ²¡æœ‰é”™é¢˜ï¼Œæ— éœ€åˆ†æã€‚"
            
            # ç»Ÿè®¡çŸ¥è¯†ç‚¹åˆ†å¸ƒ
            knowledge_points_count = {}
            category_count = {}
            difficulty_count = {}
            
            for mistake in mistakes:
                q = mistake.question
                
                # ç»Ÿè®¡çŸ¥è¯†ç‚¹
                if q.knowledge_points:
                    for kp in q.knowledge_points:
                        knowledge_points_count[kp] = knowledge_points_count.get(kp, 0) + 1
                
                # ç»Ÿè®¡åˆ†ç±»
                category = q.category or "æœªåˆ†ç±»"
                category_count[category] = category_count.get(category, 0) + 1
                
                # ç»Ÿè®¡éš¾åº¦
                difficulty_count[q.difficulty] = difficulty_count.get(q.difficulty, 0) + 1
            
            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            result = f"ğŸ” **é”™é¢˜æ·±åº¦åˆ†ææŠ¥å‘Š**\n\n"
            result += f"æ€»é”™é¢˜æ•°: {len(mistakes)}\n\n"
            
            # Topè–„å¼±çŸ¥è¯†ç‚¹
            if knowledge_points_count:
                result += "### ğŸ“Œ è–„å¼±çŸ¥è¯†ç‚¹ Top 5\n\n"
                sorted_kp = sorted(knowledge_points_count.items(), key=lambda x: x[1], reverse=True)[:5]
                for i, (kp, count) in enumerate(sorted_kp, 1):
                    percentage = count / len(mistakes) * 100
                    result += f"{i}. **{kp}**: {count}é“é”™é¢˜ ({percentage:.1f}%)\n"
                result += "\n"
            
            # é”™é¢˜åˆ†ç±»åˆ†å¸ƒ
            if category_count:
                result += "### ğŸ“‚ é”™é¢˜åˆ†ç±»åˆ†å¸ƒ\n\n"
                for category, count in sorted(category_count.items(), key=lambda x: x[1], reverse=True):
                    percentage = count / len(mistakes) * 100
                    result += f"- {category}: {count}é“ ({percentage:.1f}%)\n"
                result += "\n"
            
            # éš¾åº¦åˆ†å¸ƒ
            if difficulty_count:
                result += "### ğŸ“Š é”™é¢˜éš¾åº¦åˆ†å¸ƒ\n\n"
                for difficulty, count in sorted(difficulty_count.items(), key=lambda x: x[1], reverse=True):
                    percentage = count / len(mistakes) * 100
                    result += f"- {difficulty}: {count}é“ ({percentage:.1f}%)\n"
                result += "\n"
            
            # å­¦ä¹ å»ºè®®
            result += "### ğŸ’¡ å­¦ä¹ å»ºè®®\n\n"
            if knowledge_points_count:
                top_weak = sorted_kp[0][0]
                result += f"1. é‡ç‚¹å¤ä¹ ã€Œ{top_weak}ã€ç›¸å…³çŸ¥è¯†ç‚¹\n"
                result += f"2. å»ºè®®é’ˆå¯¹è–„å¼±ç‚¹åšä¸“é¡¹ç»ƒä¹ \n"
                result += f"3. å¯ä»¥è¯¢é—®æˆ‘è¯¦ç»†è®²è§£ä»»ä½•çŸ¥è¯†ç‚¹\n"
            
            return result
        finally:
            db.close()


class GetInterviewQuestionsTool(BaseTool):
    """è·å–é¢è¯•é¢˜çš„å·¥å…·"""
    name: str = "get_interview_questions"
    description: str = "è·å–ç”¨æˆ·å­¦ä¹ è·¯çº¿ä¸­çš„é¢è¯•é¢˜ï¼Œå¯æŒ‰åˆ†ç±»ç­›é€‰ã€‚ç”¨äºæ¨¡æ‹Ÿé¢è¯•æˆ–ç»ƒä¹ ã€‚"
    args_schema: Type[BaseModel] = GetInterviewQuestionsInput
    user_id: int = Field(default=0, description="å½“å‰ç”¨æˆ·ID")
    
    def _run(self) -> str:
        """è·å–é¢è¯•é¢˜"""
        db = SessionLocal()
        try:
            # å…ˆè·å–ç”¨æˆ·çš„å­¦ä¹ è·¯çº¿
            paths = db.query(LearningPath).filter(
                LearningPath.user_id == self.user_id
            ).all()
            
            if not paths:
                return "ç”¨æˆ·è¿˜æ²¡æœ‰åˆ›å»ºå­¦ä¹ è·¯çº¿ï¼Œæ— æ³•è·å–é¢è¯•é¢˜ã€‚"
            
            path_ids = [p.id for p in paths]
            
            # æŸ¥è¯¢é¢è¯•é¢˜ï¼ˆé»˜è®¤5æ¡ï¼‰
            questions = db.query(InterviewQuestion).filter(
                InterviewQuestion.learning_path_id.in_(path_ids)
            ).limit(5).all()
            
            if not questions:
                return "æ²¡æœ‰æ‰¾åˆ°é¢è¯•é¢˜ã€‚å»ºè®®å…ˆç”Ÿæˆå­¦ä¹ è·¯çº¿å¹¶æ·»åŠ é¢è¯•é¢˜ã€‚"
            
            result = f"æ‰¾åˆ° {len(questions)} é“é¢è¯•é¢˜ï¼š\n\n"
            for i, q in enumerate(questions, 1):
                result += f"{i}. **é¢˜ç›®**: {q.question}\n"
                result += f"   **åˆ†ç±»**: {q.category or 'æœªåˆ†ç±»'}\n"
                result += f"   **éš¾åº¦**: {q.difficulty}\n"
                result += f"   **å‚è€ƒç­”æ¡ˆ**: {q.answer[:200]}...\n\n"
            
            return result
        finally:
            db.close()


# å¯¼å‡ºæ‰€æœ‰å·¥å…·
def get_all_tools(user_id: int) -> List[BaseTool]:
    """
    è·å–æ‰€æœ‰AIåŠ©æ‰‹å·¥å…·ï¼ˆä¸ºç‰¹å®šç”¨æˆ·åˆ›å»ºï¼‰
    
    Args:
        user_id: ç”¨æˆ·IDï¼Œç”¨äºç»‘å®šåˆ°æ¯ä¸ªå·¥å…·å®ä¾‹
        
    Returns:
        å·¥å…·åˆ—è¡¨
    """
    return [
        GetMistakesTool(user_id=user_id),
        GetLearningPathTool(user_id=user_id),
        GetQuestionStatsTool(user_id=user_id),
        AnalyzeMistakesTool(user_id=user_id),
        GetInterviewQuestionsTool(user_id=user_id),
    ]

